{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both have some very large clusters.  \n",
    "Better for hierarchial because also have sub clusters.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('lingo', \"rb\") as f:\n",
    "    df_final_l = pickle.load(f)\n",
    "    labels_l = pickle.load(f)\n",
    "    k_l = pickle.load(f)\n",
    "    dist_l = pickle.load(f)\n",
    "    sil_l = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('hierarchial', \"rb\") as f:\n",
    "    df_final_h = pickle.load(f)\n",
    "    labels_h = pickle.load(f)\n",
    "    k_h = pickle.load(f)\n",
    "    dist_h = pickle.load(f)\n",
    "    sil_h = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look for Large Differences in Stats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stat_diff(stat1, stat2, n):\n",
    "    # difference in k: look for big differences\n",
    "    for i in stat1.keys():\n",
    "        diff = abs(stat2[i] - stat1[i])\n",
    "        if diff > n:\n",
    "            print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipi\n",
      "money-fx\n",
      "interest\n"
     ]
    }
   ],
   "source": [
    "stat_diff(k_h, k_l, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dmk\n",
      "platinum\n",
      "rapeseed\n",
      "income\n",
      "ipi\n",
      "lead\n",
      "tea\n",
      "livestock\n",
      "housing\n",
      "zinc\n",
      "rice\n",
      "oat\n",
      "lei\n",
      "sunseed\n",
      "gas\n",
      "soy-meal\n",
      "heat\n",
      "tin\n",
      "wpi\n",
      "silver\n",
      "jobs\n",
      "retail\n",
      "fuel\n",
      "hog\n",
      "strategic-metal\n"
     ]
    }
   ],
   "source": [
    "stat_diff(dist_h, dist_l, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orange\n",
      "sun-oil\n",
      "interest\n",
      "ipi\n",
      "lead\n",
      "corn\n",
      "wheat\n",
      "gas\n",
      "jobs\n",
      "groundnut\n",
      "wpi\n",
      "dlr\n",
      "yen\n",
      "strategic-metal\n",
      "tin\n",
      "nat-gas\n",
      "soy-oil\n",
      "cotton\n",
      "silver\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'earn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-58ebd4b39805>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mstat_diff\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msil_l\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msil_h\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-4-e92911c30efd>\u001b[0m in \u001b[0;36mstat_diff\u001b[1;34m(stat1, stat2, n)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;31m# difference in k: look for big differences\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstat1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0mdiff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstat2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstat1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdiff\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'earn'"
     ]
    }
   ],
   "source": [
    "stat_diff(sil_l, sil_h, 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Aggregate Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hierarchial: 0.7984909137451153\n",
      "Lingo: 0.8975498222974679\n"
     ]
    }
   ],
   "source": [
    "# which has on average higher distortion \n",
    "dist_h_avg = np.mean(list(dist_h.values()))\n",
    "dist_l_avg = np.mean(list(dist_l.values()))\n",
    "print('hierarchial:', dist_h_avg)\n",
    "print('Lingo:', dist_l_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hierarchial: 0.2541214271218997\n",
      "Lingo: 0.14620328094704577\n"
     ]
    }
   ],
   "source": [
    "# which has on average higher silhouette \n",
    "sil_h_avg = np.mean(list(sil_h.values()))\n",
    "sil_l_avg = np.mean(list(sil_l.values()))\n",
    "print('hierarchial:', sil_h_avg)\n",
    "print('Lingo:', sil_l_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hierarchial: 2.3333333333333335\n",
      "Lingo: 5.0\n"
     ]
    }
   ],
   "source": [
    "# number of clusters per search term on average\n",
    "k_l_avg = np.mean(list(k_l.values()))\n",
    "k_h_avg = np.mean(list(k_h.values()))\n",
    "print('hierarchial:', k_h_avg)\n",
    "print('Lingo:', k_l_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Documents per Cluster per Search Term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of documents per cluster for each search term    \n",
    "For both, grain as one cluster with basically all of the documents. Not ideal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "search  cluster\n",
       "copper  1           13\n",
       "        2           52\n",
       "grain   1           47\n",
       "        2           15\n",
       "        3          520\n",
       "tin     1            5\n",
       "        2           25\n",
       "Name: ids, dtype: int64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of documents per cluster for each search term \n",
    "grouph = df_final_h.groupby(['search','cluster']).ids.agg('count')\n",
    "grouph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "search  cluster\n",
       "copper  0            1\n",
       "        1           17\n",
       "        2            2\n",
       "        3           17\n",
       "        4           12\n",
       "grain   0          211\n",
       "        1          182\n",
       "        2           30\n",
       "        3          523\n",
       "        4          555\n",
       "        5           55\n",
       "        6          347\n",
       "        7          239\n",
       "tin     0           15\n",
       "        1           14\n",
       "Name: num, dtype: int64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfl = df_final_l.copy()[['cluster', 'ids', 'search']]\n",
    "dfl = dfl[dfl.cluster.str.len() != 0]\n",
    "dfl = pd.DataFrame([(d, tup.search) for tup in dfl.itertuples() for d in tup.cluster])\n",
    "dfl.columns = ['cluster', 'search']\n",
    "dfl['num'] = 1\n",
    "groupl = dfl.groupby(['search','cluster']).num.agg('count')\n",
    "groupl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hierarchial: 96.71428571428571\n",
      "lingo: 148.0\n"
     ]
    }
   ],
   "source": [
    "# number of documents per cluster on average \n",
    "print('hierarchial:', grouph.mean())\n",
    "print('lingo:', groupl.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tin': {1: ['strike', 'miners', 'president'], 2: ['exports', 'us', 'itc']},\n",
       " 'grain': {2: ['vs', 'last', 'estimated'],\n",
       "  1: ['corn', 'export', 'us'],\n",
       "  3: ['wheat', 'us', 'export']},\n",
       " 'copper': {1: ['cents', 'price', 'magma'],\n",
       "  2: ['mine', 'noranda', 'production']}}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tin': {0: ['miners', 'strike', 'government'], 1: ['us', 'atpc', 'exports']},\n",
       " 'grain': {4: ['nil', 'acres', 'china'],\n",
       "  3: ['corn', 'wheat', 'us'],\n",
       "  0: ['vs', 'last', 'tonnes'],\n",
       "  2: ['bushels', 'inspections', 'thous'],\n",
       "  7: ['barley', 'imports', 'ec'],\n",
       "  5: ['derivatives', 'acres', 'balance'],\n",
       "  6: ['japan', 'stocks', 'us'],\n",
       "  1: ['would', 'farm', 'lyng']},\n",
       " 'copper': {1: ['mine', 'noranda', 'fire'],\n",
       "  2: ['platinum', 'found', 'technigen'],\n",
       "  4: ['magma', 'newmont', 'subsidiary'],\n",
       "  3: ['stocks', 'refined', 'us'],\n",
       "  0: ['germans', 'ministry', 'special']}}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_l"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
