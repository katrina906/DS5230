{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both have some very large clusters.  \n",
    "Better for hierarchial because also have sub clusters.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('lingo', \"rb\") as f:\n",
    "    df_final_l = pickle.load(f)\n",
    "    labels_l = pickle.load(f)\n",
    "    k_l = pickle.load(f)\n",
    "    dist_l = pickle.load(f)\n",
    "    sil_l = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('hierarchial', \"rb\") as f:\n",
    "    df_final_h = pickle.load(f)\n",
    "    labels_h = pickle.load(f)\n",
    "    k_h = pickle.load(f)\n",
    "    dist_h = pickle.load(f)\n",
    "    sil_h = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look for Large Differences in Stats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stat_diff(stat1, stat2, n):\n",
    "    # difference in k: look for big differences\n",
    "    for i in stat1.keys():\n",
    "        diff = abs(stat2[i] - stat1[i])\n",
    "        if diff > n:\n",
    "            print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_diff(k_h, k_l, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_diff(dist_h, dist_l, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tin\n",
      "grain\n"
     ]
    }
   ],
   "source": [
    "stat_diff(sil_l, sil_h, 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Aggregate Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hierarchial: 0.7984909137451153\n",
      "Lingo: 0.8975498222974679\n"
     ]
    }
   ],
   "source": [
    "# which has on average higher distortion \n",
    "dist_h_avg = np.mean(list(dist_h.values()))\n",
    "dist_l_avg = np.mean(list(dist_l.values()))\n",
    "print('hierarchial:', dist_h_avg)\n",
    "print('Lingo:', dist_l_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hierarchial: 0.2541214271218997\n",
      "Lingo: 0.14620328094704577\n"
     ]
    }
   ],
   "source": [
    "# which has on average higher silhouette \n",
    "sil_h_avg = np.mean(list(sil_h.values()))\n",
    "sil_l_avg = np.mean(list(sil_l.values()))\n",
    "print('hierarchial:', sil_h_avg)\n",
    "print('Lingo:', sil_l_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hierarchial: 2.3333333333333335\n",
      "Lingo: 5.0\n"
     ]
    }
   ],
   "source": [
    "# number of clusters per search term on average\n",
    "k_l_avg = np.mean(list(k_l.values()))\n",
    "k_h_avg = np.mean(list(k_h.values()))\n",
    "print('hierarchial:', k_h_avg)\n",
    "print('Lingo:', k_l_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Documents per Cluster per Search Term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of documents per cluster for each search term    \n",
    "For both, grain as one cluster with basically all of the documents. Not ideal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "search  cluster\n",
       "copper  1           13\n",
       "        2           52\n",
       "grain   1           47\n",
       "        2           15\n",
       "        3          520\n",
       "tin     1            5\n",
       "        2           25\n",
       "Name: ids, dtype: int64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of documents per cluster for each search term \n",
    "grouph = df_final_h.groupby(['search','cluster']).ids.agg('count')\n",
    "grouph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "search  cluster\n",
       "copper  0            1\n",
       "        1           17\n",
       "        2            2\n",
       "        3           17\n",
       "        4           12\n",
       "grain   0          211\n",
       "        1          182\n",
       "        2           30\n",
       "        3          523\n",
       "        4          555\n",
       "        5           55\n",
       "        6          347\n",
       "        7          239\n",
       "tin     0           15\n",
       "        1           14\n",
       "Name: num, dtype: int64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfl = df_final_l.copy()[['cluster', 'ids', 'search']]\n",
    "dfl = dfl[dfl.cluster.str.len() != 0]\n",
    "dfl = pd.DataFrame([(d, tup.search) for tup in dfl.itertuples() for d in tup.cluster])\n",
    "dfl.columns = ['cluster', 'search']\n",
    "dfl['num'] = 1\n",
    "groupl = dfl.groupby(['search','cluster']).num.agg('count')\n",
    "groupl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hierarchial: 96.71428571428571\n",
      "lingo: 148.0\n"
     ]
    }
   ],
   "source": [
    "# number of documents per cluster on average \n",
    "print('hierarchial:', grouph.mean())\n",
    "print('lingo:', groupl.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tin': {1: ['strike', 'miners', 'president'], 2: ['exports', 'us', 'itc']},\n",
       " 'grain': {2: ['vs', 'last', 'estimated'],\n",
       "  1: ['corn', 'export', 'us'],\n",
       "  3: ['wheat', 'us', 'export']},\n",
       " 'copper': {1: ['cents', 'price', 'magma'],\n",
       "  2: ['mine', 'noranda', 'production']}}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tin': {0: ['miners', 'strike', 'government'], 1: ['us', 'atpc', 'exports']},\n",
       " 'grain': {4: ['nil', 'acres', 'china'],\n",
       "  3: ['corn', 'wheat', 'us'],\n",
       "  0: ['vs', 'last', 'tonnes'],\n",
       "  2: ['bushels', 'inspections', 'thous'],\n",
       "  7: ['barley', 'imports', 'ec'],\n",
       "  5: ['derivatives', 'acres', 'balance'],\n",
       "  6: ['japan', 'stocks', 'us'],\n",
       "  1: ['would', 'farm', 'lyng']},\n",
       " 'copper': {1: ['mine', 'noranda', 'fire'],\n",
       "  2: ['platinum', 'found', 'technigen'],\n",
       "  4: ['magma', 'newmont', 'subsidiary'],\n",
       "  3: ['stocks', 'refined', 'us'],\n",
       "  0: ['germans', 'ministry', 'special']}}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_l"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
